{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRa9YNrbQrJayNFwZ2CgR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/littleboss95/prueba/blob/master/Keyword_Research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-KxUZeXn_Zu3"
      },
      "outputs": [],
      "source": [
        "# @title Activar Librerias\n",
        "# Librerias para poder ejecutar el script\n",
        "\n",
        "%%capture\n",
        "\n",
        "!pip install tqdm\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm.notebook import tqdm\n",
        "import json\n",
        "import csv, sys\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import requests\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "from IPython.display import display\n",
        "from ipywidgets import GridBox, Layout\n",
        "\n",
        "from http.client import HTTPSConnection\n",
        "from base64 import b64encode\n",
        "from json import loads\n",
        "from json import dumps\n",
        "import warnings\n",
        "\n",
        "import urllib\n",
        "from string import ascii_lowercase\n",
        "\n",
        "\n",
        "# Ignorar las advertencias específicas de pandas FutureWarning\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "class RestClient:\n",
        "    domain = \"api.dataforseo.com\"\n",
        "\n",
        "    def __init__(self, username, password):\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "\n",
        "    def request(self, path, method, data=None):\n",
        "        connection = HTTPSConnection(self.domain)\n",
        "        try:\n",
        "            base64_bytes = b64encode(\n",
        "                (\"%s:%s\" % (self.username, self.password)).encode(\"ascii\")\n",
        "                ).decode(\"ascii\")\n",
        "            headers = {'Authorization' : 'Basic %s' %  base64_bytes, 'Content-Encoding' : 'gzip'}\n",
        "            connection.request(method, path, headers=headers, body=data)\n",
        "            response = connection.getresponse()\n",
        "            return loads(response.read().decode())\n",
        "        finally:\n",
        "            connection.close()\n",
        "\n",
        "    def get(self, path):\n",
        "        return self.request(path, 'GET')\n",
        "\n",
        "    def post(self, path, data):\n",
        "        if isinstance(data, str):\n",
        "            data_str = data\n",
        "        else:\n",
        "            data_str = dumps(data)\n",
        "        return self.request(path, 'POST', data_str)\n",
        "\n",
        "client = RestClient(\"jaime.sanchez@bigseo.com\", \"546754bd1dea034a\")\n",
        "#client = RestClient(\"adrian.garcia@bigseo.com\", \"7f673429c0b68694\")\n",
        "#client = RestClient(\"contact@bigseoagency.com\", \"2dc95d1f461f1045\")\n",
        "#client = RestClient(\"analytics@bigseoagency.com\", \"be18030100bbf265\")\n",
        "\n",
        "\n",
        "gmb=0\n",
        "\n",
        "access_id = \"mozscape-wfObEBqoM8\"\n",
        "secret_key = \"uaqKDOqQw4198dJiVjtuMu5jysKbdwfw\"\n",
        "\n",
        "headers = {\n",
        "    \"x-moz-token\": \"QEbJW5snXJ9LINc7u0YCWtbcNlQewDY01UjeCfLVPi961ojU8efeTIdEfD3XasrM\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "auth = (access_id, secret_key)\n",
        "url = \"https://lsapi.seomoz.com/v2/url_metrics\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Keyword Research\n",
        "\n",
        "Pais = \"Spain\" # @param [\"Spain\",\"USA\",\"Mexico\",\"United Kingdom\",\"India\",\"Romania\",\"Chile\",\"Peru\",\"Colombia\"]\n",
        "City = \"Ninguna\" # @param [\"Barcelona\",\"Madrid\",\"Asturias\",\"Ninguna\",\"Los Angeles\",\"New York\",\"Murcia\",\"Santa Cruz de Tenerife (Provincia)\",\"Badajoz (provincia)\",\"Washington\",\"London\"]\n",
        "Keyword_Principal = \"outsourcing\" # @param {\"type\":\"string\"}\n",
        "Keyword_2 = \"servicio outsourcing\" # @param {\"type\":\"string\"}\n",
        "Keyword_3 = \"agencia outsourcing\" # @param {\"type\":\"string\"}\n",
        "Keyword_4 = \"empresa outsourcing\" # @param {\"type\":\"string\"}\n",
        "Keyword_5 = \"outsourcing barcelona\" # @param {\"type\":\"string\"}\n",
        "Keyword_6 = \"outsourcing administrativo\" # @param {\"type\":\"string\"}\n",
        "Keyword_7 = \"outsourcing administrativo contable\" # @param {\"type\":\"string\"}\n",
        "Keyword_8 = \"business process outsourcing\" # @param {\"type\":\"string\"}\n",
        "Keyword_9 = \"empresa bpo\" # @param {\"type\":\"string\"}\n",
        "Keyword_10 = \"\" # @param {\"type\":\"string\"}\n",
        "Keyword_11 = \"\" # @param {\"type\":\"string\"}\n",
        "Keyword_12 = \"\" # @param {\"type\":\"string\"}\n",
        "Keyword_13 = \"\" # @param {\"type\":\"string\"}\n",
        "Keyword_14 = \"\" # @param {\"type\":\"string\"}\n",
        "Keyword_15 = \"\" # @param {\"type\":\"string\"}\n",
        "Keyword_16 = \"\" # @param {\"type\":\"string\"}\n",
        "Keyword_17 = \"\" # @param {\"type\":\"string\"}\n",
        "Keyword_18 = \"\" # @param {\"type\":\"string\"}\n",
        "Keyword_19 = \"\" # @param {\"type\":\"string\"}\n",
        "Keyword_20 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "Keywords_Semilla = [\n",
        "    Keyword_Principal, Keyword_2, Keyword_3, Keyword_4, Keyword_5,\n",
        "    Keyword_6, Keyword_7, Keyword_8, Keyword_9, Keyword_10,\n",
        "    Keyword_11, Keyword_12, Keyword_13, Keyword_14, Keyword_15,\n",
        "    Keyword_16, Keyword_17, Keyword_18, Keyword_19, Keyword_20\n",
        "]\n",
        "\n",
        "Keywords_Semilla = [kw for kw in Keywords_Semilla if kw]\n",
        "\n",
        "\n",
        "# Configuraciones de idioma y ubicación basadas en el país o ciudad seleccionados\n",
        "config = {\n",
        "    'Barcelona': {'code': 1005424, 'hl': 'es', 'Domain': 'google.es', 'country_code': 'es'},\n",
        "    'Madrid': {'code': 1005493, 'hl': 'es', 'Domain': 'google.es', 'country_code': 'es'},\n",
        "    'Murcia': {'code': 1005501, 'hl': 'es', 'Domain': 'google.es', 'country_code': 'es'},\n",
        "    'Asturias': {'code': 20286, 'hl': 'es', 'Domain': 'google.es', 'country_code': 'es'},\n",
        "    'Washington': {'code': 1027327, 'hl': 'en', 'Domain': 'google.com', 'country_code': 'us'},\n",
        "    'Los Angeles': {'code': 200803, 'hl': 'en', 'Domain': 'google.com', 'country_code': 'us'},\n",
        "    'New York': {'code': 200501, 'hl': 'en', 'Domain': 'google.com', 'country_code': 'us'},\n",
        "    'USA': {'code': 2840, 'hl': 'en', 'Domain': 'google.com', 'country_code': 'us'},\n",
        "    'Mexico': {'code': 2484, 'hl': 'es-419', 'Domain': 'google.com.mx', 'country_code': 'mx'},\n",
        "    'Spain': {'code': 2724, 'hl': 'es', 'Domain': 'google.es', 'country_code': 'es'},\n",
        "    #'Chile': {'code': 2152, 'hl': 'es-419'},\n",
        "    #'Peru': {'code': 2604, 'hl': 'es-419'},\n",
        "    #'Colombia': {'code': 2170, 'hl': 'es-419'},\n",
        "    #'Romania': {'code': 2642, 'hl': 'ro'},\n",
        "    'United Kingdom': {'code': 2826, 'hl': 'en', 'Domain': 'google.co.uk', 'country_code': 'uk'},\n",
        "    'London': {'code': 20339, 'hl': 'en', 'Domain': 'google.co.uk', 'country_code': 'uk'},\n",
        "    'Santa Cruz de Tenerife (Provincia)': {'code': 20295, 'hl': 'es', 'Domain': 'google.es', 'country_code': 'es'},\n",
        "    'Badajoz (provincia)': {'code': 1005475, 'hl': 'es', 'Domain': 'google.es', 'country_code': 'es'},\n",
        "    'India': {'code': 2356, 'hl': 'en', 'Domain': 'google.com', 'country_code': 'in'}\n",
        "}\n",
        "hl = config.get(City, config[Pais])['hl']\n",
        "code = config.get(City, config[Pais])['code']\n",
        "Domain = config.get(City, config[Pais])['Domain']\n",
        "country_code = config.get(City, config[Pais])['country_code']\n",
        "\n",
        "def get_results(query, Pais):\n",
        "    query = urllib.parse.quote_plus(query)\n",
        "    try:\n",
        "        response = requests.get(f\"https://suggestqueries.google.com/complete/search?output=chrome&google_domain={Domain}&gl={Pais}&hl={hl}&q={query}\")\n",
        "\n",
        "        if response.status_code == 200:  # Verifica que la respuesta sea OK\n",
        "            results = json.loads(response.text)\n",
        "            return results\n",
        "        else:\n",
        "            print(f\"Error {response.status_code}: {response.text}\")\n",
        "            print(f\"Keyword no válida: {query}\")\n",
        "            return None\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"RequestException: {e}\")\n",
        "        return None\n",
        "\n",
        "def format_results(results):\n",
        "    if results is None:  # Verifica que los resultados no sean None antes de proceder\n",
        "        return []\n",
        "\n",
        "    suggestions = []\n",
        "    for i, value in enumerate(results[1]):\n",
        "        suggestion = {'termino': value, 'relevance': results[4]['google:suggestrelevance'][i]}\n",
        "        suggestions.append(suggestion)\n",
        "    return suggestions\n",
        "\n",
        "def get_expanded_terms(query):\n",
        "\n",
        "    if hl in ['es', 'es-419']:\n",
        "\n",
        "      expanded_term_prefixes = ['quien es *', 'que es *', 'donde esta *', 'cuando puede *', 'por que es *',\n",
        "                              'el mejor *','la mejor *', 'barato *', 'el peor *', 'la peor *', 'es *', 'que *',\n",
        "                              'cuando *', 'porque *', 'como *', 'quien *']\n",
        "\n",
        "    if hl == 'en':\n",
        "\n",
        "      expanded_term_prefixes = ['who is *', 'what is *', 'where is *', 'when can *', 'why is *',\n",
        "                                  'the best *', 'the cheapest *', 'the worst *', 'is *', 'what *',\n",
        "                                  'when *', 'why *', 'how *', 'who *']\n",
        "\n",
        "    if hl == 'de':\n",
        "\n",
        "      expanded_term_prefixes = ['wer ist *', 'was ist *', 'wo ist *', 'wann kann *', 'warum ist *',\n",
        "                                  'das Beste *', 'das Günstigste *', 'das Schlechteste *', 'ist *', 'was *',\n",
        "                                  'wann *', 'warum *', 'wie *', 'wer *']\n",
        "\n",
        "    terms = []\n",
        "    terms.append(query)\n",
        "\n",
        "    for term in expanded_term_prefixes: #iteramos sobre los prefijos\n",
        "        terms.append(term + ' ' + query)\n",
        "        terms.append(term + ' ' + query + ' *')\n",
        "\n",
        "    for term in ascii_lowercase: # iteramos sobre el alfabeto\n",
        "        terms.append(query + ' ' + term)\n",
        "        terms.append(query + ' * ' + term)\n",
        "        terms.append(query + ' ' + term + ' *')\n",
        "\n",
        "        # Concatenaciones con el término *antes* de la query\n",
        "        terms.append(term + ' ' + query)\n",
        "\n",
        "    return terms\n",
        "\n",
        "def get_expanded_suggestions(query,Pais):\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    expanded_terms = get_expanded_terms(query)\n",
        "\n",
        "    for term in expanded_terms:\n",
        "        results = get_results(term,Pais)\n",
        "        results = format_results(results)\n",
        "        all_results = all_results + results\n",
        "        all_results = sorted(all_results, key=lambda k: k['relevance'], reverse=True)\n",
        "    return all_results\n",
        "\n",
        "def google_autocomplete(query,country, include_expanded=True):\n",
        "\n",
        "    results = get_expanded_suggestions(query,Pais)\n",
        "    df = pd.DataFrame(results)\n",
        "    return df\n",
        "\n",
        "banned_words =[]\n",
        "\n",
        "def filter_suggestions(dataframe, banned_words, current_keywords):\n",
        "    banned_words = [\"Valencia\", \"Barcelona\", \"Sevilla\", \"Zaragoza\", \"Malaga\", \"Murcia\", \"Mallorca\", \"Canaria\",\n",
        "    \"Bilbao\", \"Alicante\", \"Cordoba\", \"Valladolid\", \"Vigo\", \"Gijon\", \"Hospitalet\", \"Vitoria\",\n",
        "    \"Coruña\", \"Elche\", \"Granada\", \"Tarrasa\", \"Badalona\", \"Oviedo\", \"Cartagena\", \"Sabadell\",\n",
        "    \"Jerez\", \"Tenerife\", \"Pamplona\", \"Almeria\", \"San Sebastian\", \"Leganes\", \"Getafe\",\n",
        "    \"Burgos\", \"Albacete\", \"Alcorcon\", \"Alava\", \"Asturias\", \"Avila\", \"Badajoz\", \"Baleares\",\n",
        "    \"Caceres\", \"Cadiz\", \"Cantabria\", \"Ciudad Real\", \"Cuenca\", \"canarias\", \"Girona\", \"Guadalajara\",\n",
        "    \"Gipuzkoa\", \"Huelva\", \"Huesca\", \"Rioja\", \"Palmas\", \"Leon\", \"Lugo\", \"Madrid\", \"Navarra\",\n",
        "    \"Salamanca\", \"Segovia\", \"Tarragona\", \"Teruel\", \"Toledo\", \"Vizcaya\", \"Ceuta\", \"Antequera\",\n",
        "    \"Ibiza\", \"Menorca\", \"Formentera\", \"fuenlabrada\", \"chueca\", \"san sebastian de los reyes\", \"Palmanova\", \"uruguay\", \"chile\", \"colombia\", \"argentina\", \"mexico\", \"peru\" \"cap\", \"capitulo\",\"foro\", \"foros\", \"forocoches\"]\n",
        "\n",
        "    #banned_words_localidad = [\"uruguay\", \"chile\", \"colombia\", \"argentina\", \"mexico\", \"peru\" \"cap\", \"capitulo\",\"foro\", \"foros\", \"forocoches\", \"gratis\", \"barato\", \"gratuito\", \"barata\"]\n",
        "\n",
        "    banned_words.extend(current_keywords)\n",
        "\n",
        "    # Esta función elimina filas que contienen cualquier palabra prohibida\n",
        "    return dataframe[~dataframe['termino'].str.contains('|'.join(banned_words), case=False, na=False)]\n",
        "\n",
        "\n",
        "def get_non_brand_keywords(seed_keywords):\n",
        "    \"\"\"\n",
        "    Si seed_keywords es un string, lo convertimos a lista de un solo elemento.\n",
        "    Si es una lista de strings, simplemente la usamos.\n",
        "    \"\"\"\n",
        "    if isinstance(seed_keywords, str):\n",
        "        seed_keywords = [seed_keywords]\n",
        "\n",
        "    # Ahora en vez de hacer post_data con una sola keyword,\n",
        "    # lo hacemos con todas las que vengan en la lista seed_keywords.\n",
        "    post_data = {\n",
        "        0: {\n",
        "            'location_code': code,\n",
        "            'language_code': hl,\n",
        "            'keywords': seed_keywords\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = client.post(\n",
        "        \"/v3/keywords_data/google_ads/keywords_for_keywords/live\",\n",
        "        post_data\n",
        "    )\n",
        "\n",
        "    non_brand = []\n",
        "    if response.get(\"status_code\") == 20000:\n",
        "        for item in response[\"tasks\"][0].get(\"result\", []):\n",
        "            keyword_annotations = item.get(\"keyword_annotations\")\n",
        "            if not keyword_annotations:\n",
        "                # Si es None o no es un diccionario, saltar\n",
        "                continue\n",
        "\n",
        "            # Sacamos 'concepts'\n",
        "            concepts = keyword_annotations.get(\"concepts\", [])\n",
        "            if not concepts:\n",
        "                # Si 'concepts' está vacío o es None, saltar\n",
        "                continue\n",
        "\n",
        "            for concept in concepts:\n",
        "                if concept.get(\"name\") == \"Non-Brands\":\n",
        "                    non_brand.append(item[\"keyword\"])\n",
        "                    # Rompemos en cuanto encontramos 'Non-Brands'\n",
        "                    break\n",
        "\n",
        "    return non_brand\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Paso 1: Obtener y expandir keywords\n",
        "    initial_keywords = get_non_brand_keywords(Keywords_Semilla)\n",
        "    expanded_keywords = list(initial_keywords)\n",
        "    seen = set(expanded_keywords)\n",
        "\n",
        "    new_kws = get_non_brand_keywords(initial_keywords[:20])\n",
        "    for new_kw in new_kws:\n",
        "        if new_kw not in seen:\n",
        "            expanded_keywords.append(new_kw)\n",
        "            seen.add(new_kw)\n",
        "\n",
        "    df_ext = google_autocomplete(Keyword_Principal,country_code,True)\n",
        "\n",
        "    df_ext = filter_suggestions(df_ext, banned_words, expanded_keywords)\n",
        "\n",
        "    # Normalizar a minúsculas para eliminar duplicados insensibles a mayúsculas/minúsculas\n",
        "    df_ext.loc[:, 'termino'] = df_ext['termino'].str.lower()\n",
        "\n",
        "    # Eliminar duplicados\n",
        "    df_ext = df_ext.drop_duplicates(subset=['termino'])\n",
        "\n",
        "    # Convierte la columna 'termino' del dataframe a una lista\n",
        "    expanded_long_keywords = df_ext['termino'].tolist()\n",
        "\n",
        "    expanded_long_keywords.extend(expanded_keywords)\n",
        "\n",
        "    # Resultados finales\n",
        "    print(\"\\nKeywords iniciales:\", len(initial_keywords))\n",
        "    print(\"\\nKeywords expandidas:\", len(expanded_keywords))\n",
        "    print(\"\\nKeywords expandidas + long tails:\", len(expanded_long_keywords))\n",
        "\n",
        "  # Crea un DataFrame a partir de la lista y especifica el nombre de la columna\n",
        "    df_keywords = pd.DataFrame(expanded_long_keywords, columns=[\"Keywords\"])\n",
        "\n",
        "    # Exporta el DataFrame a un archivo Excel. (Para trabajar con .xlsx, asegúrate de tener instalado 'openpyxl' o 'XlsxWriter')\n",
        "    df_keywords.to_excel(\"expanded_long_keywords.xlsx\", index=False)\n",
        "    files.download('expanded_long_keywords.xlsx')\n",
        "\n",
        "    print(\"\\nEl archivo 'expanded_long_keywords.xlsx' se ha generado correctamente.\")\n",
        "\n",
        "# Ejecutamos si es script principal\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "ZkEJ2BXV_lUe",
        "outputId": "50c8133f-2f75-44d6-9624-6af79b396a20",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Keywords iniciales: 631\n",
            "\n",
            "Keywords expandidas: 804\n",
            "\n",
            "Keywords expandidas + long tails: 805\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e8429ed6-016d-4178-bcf0-0e19b1d5a90a\", \"expanded_long_keywords.xlsx\", 14941)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El archivo 'expanded_long_keywords.xlsx' se ha generado correctamente.\n"
          ]
        }
      ]
    }
  ]
}